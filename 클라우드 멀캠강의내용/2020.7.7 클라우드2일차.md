## 2020.7.7 클라우드2일차



클라우드 컴퓨팅 운영모델/배치모델



퍼블릭, 프라이빗 , 하이브리드, 온프레미스



인스턴스라고 말하면 그게 '가상 머신'이라고 알아들으면 됨



어플리케이션

데이터

런타임

미들웨어

운영체제

가상화

서버

스토리지(저장소)

네트워크





클라우드 컴퓨팅은 '비용 절감'이라는 측면이 매우크다



운영체제에 대해서 한마디로 정의하자면 '중개 역할'을 한다고 생각하면 됨

하나의 컴퓨터에서 2개 이상의 프로그램이 돌아가야 할 때 

하드웨어 compute resource들의 효율적인 자원 배분 등을 도와주는게 운영체제



물리적인 시스템을 호스트로 표현했으니

그 위에 있는 하이퍼바이저 위에 올라가는 OS는 GuestOS로 표현을 한다.



### **가상화 비교**

1.호스트 가상화 => 호스트 가상화에서 하이퍼바이저 제품은 VM ware WorkStation/Player 가 있다.

2.하이퍼바이저 가상화 => 하이퍼바이저 가상화는 호스트 운영체제를 제외시켜서 더 가볍고 보안이 강화됬고 하이퍼바이저  Bare-metal 이 있는데 제품으로는 VM ware ESXi 가 있다.

3.컨테이너 가상화 => 도커엔진





### 스케일업 vs 스케일아웃

스케일업 : 컴퓨터 스펙업 시키는 거구, 리부팅이 필요(어플리케이션이 한번 죽는다라는 의미),서비스 다운타임이 발생된다.



스케일아웃 : 한대로 서비스 했던 것을 비슷한 스펙의 인스턴스를 구해서 확장하는 방식으로 데이터 트래픽 처리가 용이, 서비스를 죽이지 않아도 됨





## 2장 AWS 서비스와 선택

대표적인 클라우드 서비스 밴더 => 아마존, MS, Google, IBM 등



서울 리젼도 3개의 가용 영역을 가지고 있다.

가용영역은 건물이 분리된 데이터 센터이다라고 쉽게 생각하면 됨

멀리 떨어져 있는 상태에서 자연재해가 발생했을 때 효율적



캐싱 시스템이라고 생각하면 됨 CDN(Content Delivery Network)

CDN같은 경우는 어떻게 생각하면 되냐? 스트리밍 서비스 같은 경우는 끊기지 않고 서비스가 제공되야 하잖아? 그 때 엣지 로케이션'의 일환인 CDN 같은 캐싱 서비스를 이용해서 서비스를 제공한다.

사용자가 요청을 할 때 origin server에 요청을해서 데이터를 가져오는게 아니라 origin server는 본인한테 과도한 요청이 와서 트래픽이 발생하는 것을 방지하기 위해서 Edge Location 지역에 미리 자신의 컨텐츠를 집어 넣어놓음 그러면 사용자는 origin server에 들어갈 필요 없이 Edge Location 서버에 들어가서 필요한 데이터를 가져오면 됨



### AWS 아키텍쳐(중요)

라이트세일/람다함수/빈스톡/ECS/EC2/온프레미스



0.온프레미스를 사용할 여건이 안된다면 클라우드 컴퓨팅을 이용고려

1.먼저 클라우드 밴더선정(Amazon:AWS, MS:Azure....)

2.인스턴스 설정을 고려해야함 compute resource를





람다도 일종의 PaaS 일종으로 보면 되나 정확히는 FaaS

MS로 보면 람다는 마이크로 서비스라고 생각

람다 같은 경우도 compute resource가 필요한데 람다의 런타임은 컨테이너가 될수도 있고 VM이 될수도 있다. function이기 때문에 Micro VM이라고 생각하자

Micro VM이 뭐냐? 컨테이너보다 더 안정적이고 보안에 신경을 쓴 가상화 방식,



람다는 dynamic이고, 클라이언트가 요청할 때 자원을 생성하고 종료가 되면 자원이 사라지는, 사용한 만큼만 과금을 하면 됨, 계속 Listen하고 있지 않음

ECS : 컨테이너 기반의 IaaS, static방식임 , static방식은 사용자가 요청을 해서 자원이 생성이 되면 계속 Listen하고 있는 상태임으로 대기상태에 빠짐, 계속 Listen하고 있기 때문에 사용자가 요청하지 않더라도 아주 조금이라도 리소스를 차지하고 있기 때문에 과금이 발생할 수 있음





### 3장 AWS의 IAM



처음 접근을 할 때 

사용자를 어떤식으로 사용을하는지 먼저 이해를 하고 그다음 개별 서비스,네트워크 사용하는 법을 아는게 이해가 된다.



이유는 사용자 계정을 생성하고 인스턴스를 생성할 때 그 자원들은 그 사용자에 귀속이 되기 때문에 계정에 대한 정확한 이해가 필요하다.



**IAM(Identity and Access Management)**

IAM에서는 크게 2가지를 관리한다.

'자격증명' : 사용자가 AWS 서비스를 사용할 수 있도록 인증해주는 것

'권한' : least privilege를 잘하는게 중요



요청의 주체를 인증하는 것을 '자격 증명'이라 한다.

자격증명에 부여되는 액세스 범위 '권한' => 정책 설정



"REST API" : 꼭 알아야 한다.



#### IAM 유의사항

1.루트 액세스 키를 조심해야 한다. => AWS 라는 서비스를 사용하기 위해서 사용자로 로그인을 할 수 있다. 맨처음에 Email이 AWS에서는 ID가 되는데 이 때 이 Email이 root 계정이 된다.



2.root계정과 같이 사용할 수 있는 사용자를 생성해야 한다. 그게 IAM User임 사용자에는 Admin, user1,user2 등등 내가 임의로 만들고 권한 설정만 잘해주면 됨. 이렇게 사용자를 만들어야 하는 이유는 root 계정의 액세스 키 유출을 방지하기 위해서, 목적별로 각각의 사용자를 만들고 정책설정을 잘해서 해당 서비스만 사용할 수 있게끔 만들어야 한다.



![image-20200707103644792](C:\Users\KAUstar\AppData\Roaming\Typora\typora-user-images\image-20200707103644792.png)

이건 root계정과 관련된 사용자의 URL

권한은 'policy'라고 생각하면 됨

![image-20200707104120594](C:\Users\KAUstar\AppData\Roaming\Typora\typora-user-images\image-20200707104120594.png)

위와 같이 내가 만든 사용자(s27_polly_user)가 쌤이 만들어놓은 cloud그룹에 추가가 되면 강사쌤이 연결해 놓은 AdministratorAccess가 자동으로 연결이 됨

그러나, 우리는 기존 정책에 '직접'연결하는 방법을 취할 것임

태그는 왜 쓰는거라고? 못 들었음



![image-20200707104544389](C:\Users\KAUstar\AppData\Roaming\Typora\typora-user-images\image-20200707104544389.png)

비밀 액세스 키 git에 올라가면 안된다!!!





**비용은 root계정에 charge가 된다**

그래서 개인 사용자는 알림을 못 받음



### AWS S3의 정의

어디서나 원하는 양의 데이터를 저장하고 검색할 수 있도록 구축된 객체 스토리지

**스토리지 유형**

1.객체 스토리지 : S3

2.파일 스토리지 : EFS, NAS, SAMBA(리눅스와 윈도우 간의 공유하는 방식) => 많은 솔루션을 가지고 있음

3.블록 스토리지 : iscsi, SAN, EBS 등이 있음



스토리지 밴더로는 SAN이 유명함 : NAS, iscsi 등을 제공하고 있음



그래서 리눅스를 알아야 함!!! 리눅스 마스터1급 준비하쟝





구글 클라우드에 내가 엑셀파일을 올리면 그건 binary파일의 형태로 저장이 됨 binary파일의 특징은 "read only"이다. 

파일 스토리지 기반으로 저장이 된다면 



오브젝트 스토리지와 파일 스토리지를 구분해서 생각해보자

객체 스토리지 같은 경우는 저렴하게 사용할 수 있지만 수시로 데이터가 바뀌어야 하는부분에는 적합하지 않다. 왜냐? 데이터가 바뀌면 오브젝트 자체가 전부 바뀌어야 하기 때문이다.

그러나, 파일 스토리지 방식은 전체가 바뀌는게 아니라 바뀌어야 할 부분만 바뀌기 때문에 수시로 업데이트 해야하는 데이터같은 경우 적합함 but 비싸다!



1.객체 스토리지 : S3

2.파일 스토리지 : EFS

3.블록 스토리지 : EBS

비용 : EFS>EBS>S3





#### 서버리스 컴퓨팅(Lambda)

사용자 입장에서 서버를 관리할 필요가 없다는 의미의 '서버리스'(Serverless)

개발자가 작성한 어플리케이션(기능)을 실행할 때 필요한 만큼 정확하게 자원을 사용

로드 밸런싱도 서버 부팅도 필요 없습니다. 플랫폼이 모든 작업을 수행하고 이 기능이 실행된 횟수와 시간에 따라서 비용이 부과된다.



하이퍼바이저는 가상머신과 어플리케이션 사이에 중개자 역할을 해주기 때문에 가상머신의 OS,VM 관리자라고 말할 수 있다.



## AWS Lambda

